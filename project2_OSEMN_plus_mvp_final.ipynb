{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T21:48:04.429207Z",
     "start_time": "2021-04-24T21:48:04.388693Z"
    }
   },
   "source": [
    "![example](images/top_image0.jpg)\n",
    "\n",
    "Copyright: <a href='https://www.123rf.com/profile_tomkli'>Thomas Klinder</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Increase Your Property Value and Stretch Your House Buying Budget Further</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:1.5em\">**Phase 2 Final Project**</span><br>\n",
    "* Student name: <b>Elena Kazakova</b>\n",
    "* Student pace: <b>full time</b>\n",
    "* Cohort: <b>DS02222021</b>\n",
    "* Scheduled project review date/time: <span style=\"color:red\"><b>TBD</b></span>\n",
    "* Instructor name: <b>James Irving</b>\n",
    "* Blog post URL: <span style=\"color:red\"><b>TBD</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click to jump to matching Markdown Header.*<br>\n",
    "\n",
    "- **[Introduction](#INTRODUCTION)<br>**\n",
    "- **[Obtain](#Obtain)**<br>\n",
    "- **[Scrub](#Scrub)**<br>\n",
    "- **[Explore](#Explore)**<br>\n",
    "- **[Model](#Model)**<br>\n",
    "- **[iNterpret](#iNterpret)**<br>\n",
    "- **[Conclusions/Recommendations](#Conclusions-and-Recommendation)<br>**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "This project is the Inference Analysis project of King County, WA house prices, and various factors that might affect the sales price.<br>\n",
    "This study aims to build a model(s) of house sale prices depending on the features of the property in the dataset provided. This information can be helpful for house owners, house buyers, and real estate agents in the county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this project has been downloaded from [KAGGLE site]( https://www.kaggle.com/harlfoxem/housesalesprediction?select=kc_house_data.csv). The dataset includes the information about properties sold in King County of Washington State between May 2014 and May 2015. The area consists of Seattle city area but does not include the inner city. The dataset consists of 21 dependent and independent variables and 21597 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Python tools and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.104315Z",
     "start_time": "2021-04-25T10:40:56.911825Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import json\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import sklearn.metrics as metrics\n",
    "#import plotly.graph_objects as go\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import math\n",
    "#import pickle\n",
    "import scipy.stats\n",
    "\n",
    "from matplotlib import style\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#from pandasql import sqldf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, RobustScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display, Math, Latex\n",
    "from folium import plugins\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.136321Z",
     "start_time": "2021-04-25T10:40:59.105315Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_unique_records(df):\n",
    "    unique_records=[]\n",
    "    for column in df.columns:\n",
    "        n = df[column].nunique()\n",
    "        unique_records.append((column,n))\n",
    "    print(unique_records)\n",
    "    return None\n",
    "\n",
    "def count_dups_field(field1):\n",
    "    dups = df.pivot_table(index = [field1], aggfunc ='size')\n",
    "    return dups\n",
    "\n",
    "def count_dups_fields(field1, field2):\n",
    "    dups = df.pivot_table(index = [field1, field2], aggfunc ='size')\n",
    "    return dups\n",
    "\n",
    "def remove_columns(df, y_columns=['price'], x_columns=[], exclude_columns=[], add_constant=True):\n",
    "    \n",
    "    if x_columns==[]:\n",
    "        x_columns=list(df.drop(columns=y_columns, axis=1))\n",
    "        \n",
    "    [x_columns.remove(columns) for columns in exclude_columns]\n",
    "    \n",
    "    df_x=df[x_columns]\n",
    "    df_y=df[y_columns]\n",
    "    \n",
    "    return df_x, df_y\n",
    "   \n",
    "# Function to convert geo coordinates to distance from center. I am using coordinates\n",
    "def distance_from_center(lat_coord,lon_coord):\n",
    "    R = 3959.999\n",
    "\n",
    "# I am using geo coordinates of Seattle 47.6062° N, 122.3321° W, from Wikipedia\n",
    "\n",
    "    lat1 = math.radians(47.6062)\n",
    "    lon1 = math.radians(122.3321)\n",
    "    lat2 = math.radians(lat_coord)\n",
    "    lon2 = math.radians(lon_coord)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d=R*c\n",
    "    return round(d,1)\n",
    "\n",
    "def jointplot(df):\n",
    "    sns.set_style('white')\n",
    "    for col in df.columns:\n",
    "        g=sns.jointplot(x=col, y='price', data=df, size=5, kind='reg', marginal_ticks=True,\n",
    "                        joint_kws={'line_kws':{'color':'green'}}, height=15, space=0.7)\n",
    "        name=col\n",
    "        R2,p= scipy.stats.pearsonr(x=df[col], y=df.price)\n",
    "        g.fig.suptitle('For {}: R2 coefficient is {}, p-value is {}'.format(name, round(R2,4),p))\n",
    "        g.fig.tight_layout()\n",
    "        g.fig.subplots_adjust(top=0.85)\n",
    "        \n",
    "    return None\n",
    "\n",
    "def r2_p(df):\n",
    "    for col in df.columns:\n",
    "        name=col\n",
    "        R2,p= scipy.stats.pearsonr(x=df[col], y=df.price)\n",
    "        print('For {}: R2 coefficient is {}, p-value is {}'.format(name, round(R2,4),p))\n",
    "    return None\n",
    "\n",
    "# This is a snippet from https://www.analyticsvidhya.com/blog/2020/03/what-is-multicollinearity/\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "\n",
    "# This is a snippet from https://atmamani.github.io/cheatsheets/seaborn/seaborn_cheat_sheet_1/\n",
    "def distribution(column):\n",
    "    col_mean = column.mean()\n",
    "    col_sd = column.std()\n",
    "    skew_val = stats.skew(column, bias=False)\n",
    "    kurt_val = stats.kurtosis(column,bias=False)\n",
    "    \n",
    "    ax = sns.distplot(column, kde_kws={\"color\": \"r\", \"lw\": 2, \"label\": \"KDE\", \"bw_adjust\": 3})\n",
    "        \n",
    "    ax.axvline(x=col_mean, color='black', linestyle='dashed')\n",
    "\n",
    "    ax.axvline(x=col_mean + col_sd, color='red', linestyle='dotted')\n",
    "    ax.axvline(x=col_mean - col_sd, color='red', linestyle='dotted')\n",
    "\n",
    "    ax.set_title('$\\mu = {}$ | $\\sigma = {}$ | Skew = {} | Kurtosis = {}'.\n",
    "                 format(round(col_mean, 2), round(col_sd, 2), round(skew_val,2), round(kurt_val,2)))\n",
    "    \n",
    "    plt.subplots_adjust(top=0.5)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return None\n",
    "\n",
    "def boxen_plot(df,colname):\n",
    "    ax = sns.catplot(x=df[colname], y=df.price/1000000, kind=\"boxen\",\n",
    "                 data=df.sort_values(colname), height=7, aspect=8/5)\n",
    "    ax.set_xticklabels(fontsize=12)\n",
    "    ax.set_yticklabels(fontsize=12)\n",
    "    plt.ylabel('Price in millions', fontsize=15)\n",
    "    plt.xlabel(colname,fontsize=15)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "#Zipcode choropleth maps with average values per a zipcode (King County)\n",
    "def map_choropleth_zip(df, column, title, column_name):\n",
    "    fig=px.choropleth_mapbox(data_frame=df, locations='zipcode', geojson=KC_zip_json, color=column, \n",
    "                         mapbox_style='open-street-map', zoom=8.5, height=900, featureidkey='properties.ZCTA5CE10', \n",
    "                        center={'lat': 47.403768, 'lon': -122.005863}, opacity=0.4,\n",
    "                        color_continuous_scale=px.colors.sequential.YlOrRd,\n",
    "                        title=title,\n",
    "                        template = \"plotly_dark\", \n",
    "                        labels={\n",
    "                            column: column_name})\n",
    "    fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_size=16,\n",
    "    font_color=\"white\",\n",
    "    title_font_family=\"Arial\",\n",
    "    title_font_color=\"white\",\n",
    "    title_font_size=20)\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title={\n",
    "        'y':0.98,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "    })\n",
    "    \n",
    "    fig.show()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.200335Z",
     "start_time": "2021-04-25T10:40:59.138322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing raw data\n",
    "df=pd.read_csv('data/kc_house_data.csv')\n",
    "pd.set_option('display.width', 1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.216339Z",
     "start_time": "2021-04-25T10:40:59.201337Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.232343Z",
     "start_time": "2021-04-25T10:40:59.217339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying tuples of fields and unique records in them\n",
    "count_unique_records(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.248346Z",
     "start_time": "2021-04-25T10:40:59.233344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding all duplicate IDs\n",
    "\n",
    "df_a=pd.DataFrame(count_dups_field('id'))\n",
    "df_a.columns=['count']\n",
    "df_a = df_a[df_a['count'] > 1].sort_values('count', ascending=False)\n",
    "df_a.reset_index(level=0, inplace=True)\n",
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.919001Z",
     "start_time": "2021-04-25T10:40:59.250347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Listing duplicate IDs and associated dataset records to find out the reason they are in the file twice\n",
    "\n",
    "df_dup=pd.DataFrame()\n",
    "for i in range(len(df_a)):\n",
    "    df_dup=df_dup.append(df[df.id==df_a.id[i]], ignore_index=True)\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:30:50.434624Z",
     "start_time": "2021-04-13T02:30:50.426622Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">The inspection of the records shows that the records with duplicate IDs have different sale dates and sale prices. However, all other features remain the same. Records with the same set of predictors but different prices would introduce additional \"noise\" to the data. Because there are only 353 records with that problem, I decided to drop them from the dataset.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.951007Z",
     "start_time": "2021-04-25T10:40:59.920001Z"
    }
   },
   "outputs": [],
   "source": [
    "#listing datatype, number of null values, min and max values in the fields of the dataset\n",
    "\n",
    "fields1=['bedrooms','bathrooms','floors','waterfront', 'view','condition','grade']\n",
    "fields2=['sqft_lot15', 'sqft_living15','yr_renovated','yr_built','sqft_above','sqft_living','sqft_lot']\n",
    "for column in df.columns:\n",
    "    type_=df[column].dtypes\n",
    "    num_nulls=df[column].isna().sum()\n",
    "    min_=0\n",
    "    max_=0\n",
    "    unique_=[0]\n",
    "    if column in fields1:\n",
    "        unique_=df[column].unique()\n",
    "        unique_.sort()\n",
    "    else:\n",
    "        if column in fields2:\n",
    "            min_=df[column].min()\n",
    "            max_=df[column].max()\n",
    "        else:\n",
    "            continue\n",
    "    print('Column name:', column)\n",
    "    print('Type:', type_)\n",
    "    print('Number of null values', num_nulls)\n",
    "    print('Unique values:',unique_)\n",
    "    print('Min value: ', min_, 'Max value:', max_)\n",
    "    print('***********************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T20:31:07.297049Z",
     "start_time": "2021-04-12T20:31:06.955983Z"
    }
   },
   "source": [
    "The file has 21597 records with 21 columns, out of which 11 columns have integer values, 8 are real numbers, and 2 are strings.<br>\n",
    "    The annotation to the fields and associated data<br> (link to the definitions [here](https://github.com/emilyageller/king_county_house_prices))\n",
    "* <b>id:</b> Unique ID for each home sold\n",
    "\n",
    "    1. no NULL values<br>\n",
    "    2.integer numbers<br>\n",
    "    3.176 duplicate records\n",
    "><span style=\"color:red\"><b>353 rows to be dropped</b></span>\n",
    "\n",
    "* **date:** Date of the sale\n",
    ">no NULL values<br>\n",
    "string<br>\n",
    "\n",
    "><span style=\"color:red\"><b>Convert to DateTime type</b></span>\n",
    "\n",
    "* **price** - Price of each home sold\n",
    ">no NULL values<br>\n",
    "Real numbers<br>\n",
    "Minimum price: 78000<br>\n",
    "Maximum price: 7700000\n",
    "\n",
    "* **bedrooms** - Number of bedrooms\n",
    ">no NULL values<br>\n",
    ">Integer numbers, between 1 and 33\n",
    "\n",
    "* **bathrooms** - Number of bathrooms, where .5 accounts for a room with a toilet but no shower\n",
    ">no NULL values<br>\n",
    ">Real numbers, between 0.5 and 8.0\n",
    "\n",
    "* **sqft_living** - Square footage of the house interior living space\n",
    ">No NULL values<br>\n",
    "Integer numbers<br>\n",
    "Minimum value: 370<br>\n",
    "Maximum value: 13540\n",
    "\n",
    "* **sqft_lot** - Square footage of the land lot\n",
    ">No NULL values<br>\n",
    "Integer numbers<br>\n",
    "Minimum value: 520<br>\n",
    "Maximum value: 1651359\n",
    "\n",
    "* **floors** - Number of floors\n",
    ">no NULL values<br>\n",
    ">Real numbers, between 1.0 and 3.5\n",
    "\n",
    "* **waterfront** - A categorical variable for whether the house was overlooking the waterfront or not\n",
    ">**2376** NULL values<br>\n",
    ">Real numbers, only two values 1.0 and 0.0<br>\n",
    "\n",
    "><span style=\"color:red\"><b>Convert to a categorical variable<br>\n",
    "Waterfront, not Waterfront</b></span><br><br>\n",
    "><span style=\"color:red\"><b>Replace NULL values with \"Missing\" category</b></span>\n",
    "\n",
    "* **view** - A categorical variable describing how good the view of the property was\n",
    ">**63** NULL values<br>\n",
    ">Real numbers: 1.0, 2.0, 3.0, 4.0<br>\n",
    "\n",
    "><span style=\"color:red\"><b>Convert to a categorical variable<br>\n",
    "Poor, Fair, Good Excellent</b></span>\n",
    "\n",
    "><span style=\"color:red\"><b>Replace NULL values with \"Missing\" category</b></span>\n",
    "\n",
    "* **condition** - A categorical variable describing the condition of the house\n",
    ">no NULL values<br>\n",
    ">Integer numbers, between 1 and 5<br>\n",
    "\n",
    "><span style=\"color:red\"><b>Convert to a categorical variable<br>\n",
    "Poor, Fair, Good, Very Good, Excellent</b></span>\n",
    "\n",
    "* **grade** - A categorical variable describing the quality of construction, from 1 to 13; 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.\n",
    ">no NULL values<br>\n",
    ">Integer numbers, between 3 and 13<br>\n",
    "\n",
    "* **sqft_above** - The square footage of the interior housing space that is above ground level\n",
    ">No NULL values<br>\n",
    "Integer numbers<br>\n",
    "Minimum value: 370<br>\n",
    "Maximum value: 9410\n",
    "\n",
    "* **sqft_basement** - The square footage of the interior housing space that is below ground level\n",
    ">No NULL values<br>\n",
    "String<br>\n",
    "\n",
    "><span style=\"color:red\"><b>Convert to integer</b></span><br>\n",
    "\n",
    "* **yr_built** - The year the house was initially built\n",
    ">No NULL values<br>\n",
    "Integer numbers<br>\n",
    "Minimum value: 1900<br>\n",
    "Maximum value: 2015\n",
    "\n",
    "* **yr_renovated** - The year of the last house renovation\n",
    ">**3842** NULL values<br>\n",
    ">Real numbers, between 0.0 and 2015.0<br>\n",
    "\n",
    "><span style=\"color:red\"><b>Convert to integer</b></span><br>\n",
    "\n",
    "* **zipcode** - What zipcode area the house is in\n",
    ">no NULL values<br>\n",
    "Integer numbers, 70 unique values<br>\n",
    "\n",
    "><span style=\"color:red\"><b>Convert to categorical variable or drop</b></span>\n",
    "\n",
    "* **lat** - Lattitude\n",
    ">no NULL values<br>\n",
    ">Real numbers\n",
    "\n",
    "* **long** - Longitude\n",
    ">no NULL values<br>\n",
    ">Real numbers\n",
    "\n",
    "* **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbors\n",
    ">No NULL values<br>\n",
    "Integer numbers<br>\n",
    "Minimum value: 399<br>\n",
    "Maximum value: 6210\n",
    "\n",
    "* **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbors\n",
    ">No NULL values<br>\n",
    "Integer numbers<br>\n",
    "Minimum value: 651<br>\n",
    "Maximum value: 871200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial cleaning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:40:59.967010Z",
     "start_time": "2021-04-25T10:40:59.952008Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Dropping duplicate rows for houses sold twice in the timeframe of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:00.015022Z",
     "start_time": "2021-04-25T10:40:59.968011Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dropping duplicate rows for houses sold twice in the timeframe of the dataset\n",
    "df = df.drop_duplicates(subset='id', keep=\"first\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Converting the 'date' field to DateTime formate and making sure it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:00.047029Z",
     "start_time": "2021-04-25T10:41:00.016022Z"
    }
   },
   "outputs": [],
   "source": [
    "# date string to datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:00.095040Z",
     "start_time": "2021-04-25T10:41:00.048029Z"
    }
   },
   "outputs": [],
   "source": [
    "#Checking if the conversion went OK\n",
    "mask = (df['date'] > '9/24/2014') & (df['date'] <= '4/22/2015')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Locations of the houses with missing 'waterfront' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:00.111043Z",
     "start_time": "2021-04-25T10:41:00.096039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Possible strategies:\n",
    "# 1. Check if there are waterfront properties among neighbors within a certain distance range\n",
    "# 2. Make a map and place properties with missing values on it visually\n",
    "# 3. What is the longitude of the bay shore? Any house with a missing value too far away from it \n",
    "#    should have their waterfront value set to 0. Hopefully, it will eliminate most of the missing values in this field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:00.127046Z",
     "start_time": "2021-04-25T10:41:00.112043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Leaving just coordinates of the waterfront NaN properties\n",
    "mask = (df['waterfront'].isna())\n",
    "df_wf_na_coord=df.loc[mask]\n",
    "df_wf_na_coord.drop(df_wf_na_coord.columns[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,19,20]], axis=1, inplace=True)\n",
    "\n",
    "df_wf_na_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Visual assesment of the houses with Null value in the 'waterfront column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.118099Z",
     "start_time": "2021-04-25T10:41:00.128047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the map based on the Wikipedia location of Seattle\n",
    "KCMap = folium.Map(location=[47.6171,-122.3249],  tiles='Stamen Terrain', zoom_start=9)\n",
    "\n",
    "# for each row in the KC_house dataset with missing waterfront value, \n",
    "# plot the corresponding latitude and longitude on the map\n",
    "for index, row in df_wf_na_coord.iterrows():\n",
    "    folium.CircleMarker((row['lat'], row['long']), radius=1, weight=2, \n",
    "                        color='red', fill_color='red', fill_opacity=.5).add_to(KCMap)\n",
    "    \n",
    "display(KCMap)\n",
    "# adding the heatmap\n",
    "KCMap.add_child(plugins.HeatMap(data=df_wf_na_coord[['lat', 'long']], radius=20, blur=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.134112Z",
     "start_time": "2021-04-25T10:41:02.119077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying\n",
    "# the percentage of waterfront properties in the dataset with missing waterfront values,\n",
    "# the percentage of waterfront properties in the full dataset\n",
    "# The systemic error introduced to the full dataset if missing waterfront values would be replaced with 0\n",
    "\n",
    "a=round((20/len(df_wf_na_coord))*100,3)\n",
    "\n",
    "b=round((len(df[df['waterfront'] == 1])/len(df)*100),2)\n",
    "\n",
    "c=round(round(((len(df[df['waterfront'] == 1])+20)/len(df)*100),3)-round((len(df[df['waterfront'] == 1])/len(df)*100),3),3)\n",
    "\n",
    "print('{}%, {}%, {}%'.format(a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">It is self-evident from the visuals above that the vast majority of the houses are located inland. Simple zooming in the maps allows a rough counting of alleged waterfront properties. The estimate is approximately 20 waterfront houses. It is 0.85% of all properties with no value in 'waterfront column (2353). In the primary dataset, the percentage of waterfront properties out of the total number of properties is 0.68%. The numbers above indicate that replacing the NaN values with 0 would introduce a systemic error of 0.01% to the whole system.<br>\n",
    "    <b>Conclusion:</b> The NULL values in the 'waterfront' column will be replaced with 0.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Replacing NULL values in 'waterfront' column and converting the column to the integer datatype to make it categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.149408Z",
     "start_time": "2021-04-25T10:41:02.135298Z"
    }
   },
   "outputs": [],
   "source": [
    "#Replacing NaN values in 'waterfront' column\n",
    "\n",
    "df.loc[df.waterfront.isna(),'waterfront']=0\n",
    "df.waterfront=df.waterfront.astype('int64')\n",
    "\n",
    "\n",
    "subset_df = df[df['waterfront'] == 1]\n",
    "count = len(subset_df)\n",
    "print(count)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.165072Z",
     "start_time": "2021-04-25T10:41:02.150407Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Replacing NULL values in waterfront  and view field  using IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.181079Z",
     "start_time": "2021-04-25T10:41:02.166072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping columns with str datatypes to use IterativeImputer on the rest\n",
    "\n",
    "df_to_II=df.drop(['date','id','zipcode','sqft_basement'],axis=1)\n",
    "df_to_II.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.370365Z",
     "start_time": "2021-04-25T10:41:02.182079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using IterativeImputer to fill in Nan cells\n",
    "\n",
    "imp = IterativeImputer(max_iter=10,random_state=0)\n",
    "imp.fit(df_to_II)\n",
    "imputed_df_to_II = imp.transform(df_to_II)\n",
    "imputed_df = pd.DataFrame(imputed_df_to_II, columns=df_to_II.columns)\n",
    "imputed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.402373Z",
     "start_time": "2021-04-25T10:41:02.371366Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.434379Z",
     "start_time": "2021-04-25T10:41:02.405373Z"
    }
   },
   "outputs": [],
   "source": [
    "imputed_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.450383Z",
     "start_time": "2021-04-25T10:41:02.436380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a subset of records with imputed NaN values\n",
    "\n",
    "subset_df = imputed_df[(imputed_df['yr_renovated'] < 1934) & (imputed_df['yr_renovated'] != 0)]\n",
    "count = len(subset_df)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.466387Z",
     "start_time": "2021-04-25T10:41:02.451383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Listing Imputed NaN values in yr_renovated column\n",
    "list_unique=list(df.yr_renovated.unique())\n",
    "\n",
    "inverse_boolean_series = ~imputed_df.yr_renovated.isin(list_unique)\n",
    "inverse_filtered_df = imputed_df[inverse_boolean_series]\n",
    "inverse_filtered_df.yr_renovated.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.482390Z",
     "start_time": "2021-04-25T10:41:02.467387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Listing Imputed NaN values in waterfront column\n",
    "inverse_boolean_series = ~imputed_df.waterfront.isin([0,1])\n",
    "inverse_filtered_df = imputed_df[inverse_boolean_series]\n",
    "inverse_filtered_df.waterfront.sort_values() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.498394Z",
     "start_time": "2021-04-25T10:41:02.483390Z"
    }
   },
   "outputs": [],
   "source": [
    "# Listing Imputed NaN values in view column\n",
    "inverse_boolean_series = ~imputed_df.view.isin([0,1,2,3,4])\n",
    "inverse_filtered_df = imputed_df[inverse_boolean_series]\n",
    "inverse_filtered_df.view.sort_values() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Conclusion:</b>  Based on the results of IterativeImputer the original approach of replacing missing values in 'waterfront', 'yr_renovated', and 'view'  with 0 will be taken<br>    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T05:56:24.642262Z",
     "start_time": "2021-04-14T05:56:24.634270Z"
    }
   },
   "source": [
    "#### 4. Replacing NULL values in yr_renovated column with 0. value and changing the type to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.514397Z",
     "start_time": "2021-04-25T10:41:02.499394Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.yr_renovated.isna(),'yr_renovated']=0.0\n",
    "df.yr_renovated=df.yr_renovated.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Replacing '?' values in 'sqft_basement' column with 0. value and changing the type to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.562408Z",
     "start_time": "2021-04-25T10:41:02.515398Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[(df.sqft_basement == '?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.578412Z",
     "start_time": "2021-04-25T10:41:02.563409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting '?' sqft_basement values to 0 and listing unique values\n",
    "df.loc[(df.sqft_basement == '?'),'sqft_basement']='0.0'\n",
    "\n",
    "df.sqft_basement=df.sqft_basement.astype('float64')\n",
    "\n",
    "df.sqft_basement=df.sqft_basement.astype('int64')\n",
    "\n",
    "#Checking the result\n",
    "df_temp=df.sqft_basement.unique()\n",
    "list1 = df_temp.tolist()\n",
    "list1.sort()\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Replacing NULL values in 'view' column with 0.0 and making it integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.594415Z",
     "start_time": "2021-04-25T10:41:02.579413Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.view.isna(),'view']=0\n",
    "df.view=df.view.astype('int64')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub and Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping non-needed fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.626422Z",
     "start_time": "2021-04-25T10:41:02.595416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping 'zipcode' variable because I think there are better indicators of a location.\n",
    "# Zipcodes boundaries are usually drawn out of convenience for postal services or\n",
    "# other more formal reasons than geographic location\n",
    "\n",
    "# Dropping 'id' field\n",
    "# Resettingh index because of the removal of the duplicates\n",
    "\n",
    "df_1=df\n",
    "df_1=df_1.drop(['id','zipcode'], axis=1)\n",
    "#df_1.tail()\n",
    "\n",
    "\n",
    "df_1.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>21420</b> records out of the original <b>21597</b> left\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring distributions and correlation of original variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables: Investigating distributions and correlations between the original, minimally processed predictors and the target (price) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms and pair correlations of the original predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:02.642426Z",
     "start_time": "2021-04-25T10:41:02.627424Z"
    }
   },
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:14.437089Z",
     "start_time": "2021-04-25T10:41:02.643427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Investigating histograms\n",
    "\n",
    "df_1.hist(figsize=(20, 30), bins='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on the histograms above**\n",
    "> 1. The following variables should be considered categorical:\n",
    ">>Waterfront<br>\n",
    "Condition<br>\n",
    "View<br>\n",
    "> 2. sqft_basement, sqft_lot, sqft_lot15, and yr_renovated have a large number of zeros and are strong candidates for removal of outliers and/or engineered variables<br>\n",
    "> 3. Latitudes and Longitudes can be used as descriptors of a geographic location of a property. However, I think there is  a better variable to describe the location of a property, a distance from the center of the city, which can be calculated from geocoordinates.<br>\n",
    "    >4. The target variable, the price of the property, has a strong positive skew attributed to outliers in the higher price bracket. The strategy is to **remove the outliers and to transform the variable** to make it more normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:14.484603Z",
     "start_time": "2021-04-25T10:41:14.438089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for correlations between the variables with Pearson coefficient between 1 and 0.3\n",
    "# I am using the same approach and reusing the code from Lesson 19\n",
    "\n",
    "df_coeff=df_1.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "df_coeff['pairs'] = list(zip(df_coeff.level_0, df_coeff.level_1))\n",
    "df_coeff.set_index(['pairs'], inplace = True)\n",
    "df_coeff.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "df_coeff.columns = ['cc']\n",
    "df_coeff.drop_duplicates(inplace=True)\n",
    "df_coeff[((df_coeff.cc>.3) & (df_coeff.cc <1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The variables which have the strongest correlations with the price are**<br>\n",
    "* sqft_living<br>\n",
    "* grade<br>\n",
    "* sqft_above<br>\n",
    "* sqft_living15<br>\n",
    "* bathrooms<br>\n",
    "* view<br>\n",
    "* bedrooms<br>\n",
    "*lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing an intermediate dataframe and removing some outliers from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:14.515611Z",
     "start_time": "2021-04-25T10:41:14.485605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing extreme values from sqft_lot, sqft_lot15, bathrooms, and price\n",
    "# On one hand, it can be left to the step of outlier removal, on the other doing it now\n",
    "# will help a visual investigation of the distributions of the variables mentioned above\n",
    "\n",
    "df_2=df_1[(df_1.sqft_lot >100) & (df_1.sqft_lot<40000)]\n",
    "\n",
    "df_2=df_2[(df_2.sqft_lot15 >100) & (df_2.sqft_lot15<40000)]\n",
    "\n",
    "df_2=df_2[df_2.price < 2500000]\n",
    "\n",
    "df_2=df_2[df_2.bedrooms < 30]\n",
    "\n",
    "df_2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:15.249051Z",
     "start_time": "2021-04-25T10:41:14.516611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a new categorical variable: month\n",
    "df_2['month'] = pd.to_datetime(df_2['date']).dt.month\n",
    "\n",
    "# Creating a new numerical variable: distance (distance from center)\n",
    "df_2['distance'] = df_2.apply(lambda row: distance_from_center(row.lat,abs(row.long)), axis=1) \n",
    "\n",
    "# Creating a new categorical variable: basement_exists (1/0), integer datatype\n",
    "df_2.loc[(df_2['sqft_basement'] > 50), 'basement_exists'] = 1\n",
    "df_2.loc[(df_2['sqft_basement'] <= 50), 'basement_exists'] = 0\n",
    "df_2.basement_exists=df_2.basement_exists.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:15.265055Z",
     "start_time": "2021-04-25T10:41:15.250052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a new categorical variable (integer datatype) renovation_done with values [0,1,2,3,4]\n",
    "\n",
    "# 0 representing renovation never done on houses more than 9 years old (yr_built between 2015 and 2006)\n",
    "# 1 representing renovation done more than or equal 50 years ago\n",
    "# 2 representing renovation done between 30 and 49 years ago\n",
    "# 3 representing renovation done between 29 and 10 years ago\n",
    "# 4 representing renovation done between 9 and 1 year ago OR houses built less or equal 9 years ago\n",
    "#   (yr_built between 2015 and 2006)\n",
    "\n",
    "df_2.loc[((df_2['yr_renovated'] == 0) & (df_2['yr_built'] < 2006)), 'renovation_done'] = 0\n",
    "df_2.loc[((2015-df_2['yr_renovated'] >= 50) & (df_2['yr_renovated'] != 0)), 'renovation_done'] = 1\n",
    "df_2.loc[((2015-df_2['yr_renovated'] < 50) & (2015-df_2['yr_renovated'] >= 30)), 'renovation_done'] = 2\n",
    "df_2.loc[((2015-df_2['yr_renovated'] < 30) & (2015-df_2['yr_renovated'] >= 10)), 'renovation_done'] = 3\n",
    "df_2.loc[((2015-df_2['yr_renovated'] < 10) | (df_2['yr_built'] >= 2006)), 'renovation_done'] = 4\n",
    "\n",
    "df_2.renovation_done=df_2.renovation_done.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:15.297062Z",
     "start_time": "2021-04-25T10:41:15.266055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping sqft_basement variable\n",
    "# Dropping latitude & longtitude variable\n",
    "# Dropping date variable# Resetting index due to removal of records with extreme values in \n",
    "# sqft_lot, sqft_lot15, bathrooms and price\n",
    "\n",
    "df_2=df_2.drop(['sqft_basement','date', 'lat','long','yr_renovated'], axis=1)\n",
    "\n",
    "df_2=df_2.reset_index(drop=True)\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T16:02:58.260794Z",
     "start_time": "2021-04-24T16:02:58.247792Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>df_2</b> DataFrame<br><br><b>20015</b> records out of the original <b>21597</b> left\n",
    "    </div><br>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Index reset</b>\n",
    "    </div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting numerical variables against the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:15.313065Z",
     "start_time": "2021-04-25T10:41:15.298062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping categorical variables to simplify the analysis of the numerical ones\n",
    "\n",
    "df_num1=df_2.drop(['waterfront','view','condition','basement_exists','renovation_done','month'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:15.329069Z",
     "start_time": "2021-04-25T10:41:15.314168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying the Coefficients of Determination and p-values for the remaining variables\n",
    "r2_p(df_num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:30.720292Z",
     "start_time": "2021-04-25T10:41:15.330070Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Joint plot of the original (not altered) numerical variables\n",
    "jointplot(df_num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:30.735799Z",
     "start_time": "2021-04-25T10:41:30.721293Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:30.751803Z",
     "start_time": "2021-04-25T10:41:30.736800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing extreme values from bedrooms, bathrooms, floors, and distance\n",
    "# The observations with the extreme values of these variables are visually identifiable \n",
    "\n",
    "df_num2=df_num1[(df_num1.bedrooms < 9) & (df_num1.bathrooms < 5.5) &(df_num1.distance < 30) \n",
    "               & (df_num1.floors<3.5)]\n",
    "df_num2.drop(['yr_built'], axis=1, inplace=True)\n",
    "df_num2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:30.767806Z",
     "start_time": "2021-04-25T10:41:30.752803Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>df_num2</b> DataFrame<br><br><b>19811</b> records out of original <b>21597</b> left\n",
    "    </div><br>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Index reset</b>\n",
    "    </div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:44.867950Z",
     "start_time": "2021-04-25T10:41:30.768807Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Joint plot of numerical variables after adjustments\n",
    "jointplot(df_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:44.883954Z",
     "start_time": "2021-04-25T10:41:44.868951Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_p(df_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:44.899958Z",
     "start_time": "2021-04-25T10:41:44.884954Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing numerical predictors correlation with the price and with each other using heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:45.778154Z",
     "start_time": "2021-04-25T10:41:44.900958Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(df_num2.corr(), cmap=\"cubehelix\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:45.793661Z",
     "start_time": "2021-04-25T10:41:45.779154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bedrooms is relatively highly correlated with bathrooms and sqft_living; correlations of floors, sqft_lot and sqft_lot15 \n",
    "# with prices are low. Dropping these variables\n",
    "\n",
    "df_num3=df_num2.drop(['bedrooms','sqft_lot','sqft_lot15','floors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:46.273768Z",
     "start_time": "2021-04-25T10:41:45.794661Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(df_num3.corr(), cmap=\"cubehelix\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:46.289771Z",
     "start_time": "2021-04-25T10:41:46.274768Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_p(df_num3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the distribution of the remaining numerical predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:48.575785Z",
     "start_time": "2021-04-25T10:41:46.290771Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting KDE and distribution plots of the remaining variables\n",
    "\n",
    "continuous=['price','sqft_living','sqft_living15','sqft_above','distance']\n",
    "for col in continuous:\n",
    "    fig, ax =plt.subplots(figsize=(5, 5))\n",
    "    distribution(df_num3[col])\n",
    "\n",
    "discrete=['bathrooms','grade']\n",
    "for col in discrete:\n",
    "    fig, ax =plt.subplots(figsize=(5, 5))\n",
    "    ax = sns.distplot(df_num3[col], bins=10, kde_kws={\"color\": \"r\", \"lw\": 2, \"label\": \"KDE\", \"bw_adjust\": 4})\n",
    "    skew_val = stats.skew(df_num3[col], bias=False)\n",
    "    kurt_val = stats.kurtosis(df_num3[col],bias=False)\n",
    "    print('Column: {} | Skewness = {} | Kurtosis = {}'.\n",
    "                 format(col, round(skew_val,2), round(kurt_val,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">All but one variable (distance) are left shifted, which is indicated by the skewness values >1, with price has the most skewed distribution. Because the skewness it to the left (positive values), the log transformation might be needed to normalize the variables. Kurtosis values for all variables are different from 0 (Pearson's definition of kurtosis of a normal distribution). <br>\n",
    "    Price distribution is highly <b>Leptokurtic</b>, other variables are slightly <b>Leptokurtic</b> (sqft_living, sqft_above, sqft_living15, grade), slightly <b>Platykurtic</b> (distance) or almost <b>Mesokurtic</b> (bathrooms)</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:49.405971Z",
     "start_time": "2021-04-25T10:41:48.576786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diamond box plots for descrete numerical variables\n",
    "\n",
    "discrete=['bathrooms','grade']\n",
    "for col in discrete:\n",
    "\n",
    "    ax = sns.catplot(x=col, y='price', kind=\"boxen\",\n",
    "            data=df_num3.sort_values(col), height=9, aspect=12/9)\n",
    "    ax.set_xticklabels(rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_yticklabels(fontsize=12)\n",
    "    plt.ylabel('Price in millions', fontsize=15)\n",
    "    plt.xlabel(col, fontsize=15);\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> Based on the distribution plots, variable 'bathroom' has a symmetrical distribution (Skewness is 0.28), with a very low kurtosis (0.09) indicative of a <b>Mesokurtic</b> curve (Gaussian distribution has a kurtosis of 0 by Pearson's definition used by scipy.stats.kurtosis method)<br>\n",
    "Variable 'grade' is slightly skewed to the right (0.73) and relatively low kurtosis, slightly above 1.<br>\n",
    "The pronounced correlation of these variables with the price is identifiable in the box plots above. The plots show that the numbers of outliers in the distribution of the variables are reasonable. Both variables have a wider range of values in the higher price brackets.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables: Exploring Mutual Correlation Coefficients and Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using VIF as an indicator of collinearity between independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:49.453982Z",
     "start_time": "2021-04-25T10:41:49.406971Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_vif(df_num3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:49.469985Z",
     "start_time": "2021-04-25T10:41:49.454982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping fields that have high VIF. I decided to leave in sqft_living versus sqft_living15 due to the fact that it is\n",
    "# easier to interpret in a model and it is a feature under control of a property owner (versus sqft_living15 which is\n",
    "# a charecteristic of a neighborhood)\n",
    "\n",
    "df_num4=df_num3.drop(['price','sqft_above','sqft_living15'],axis=1)\n",
    "\n",
    "calc_vif(df_num4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson coefficients analysis of the remaining independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:49.485989Z",
     "start_time": "2021-04-25T10:41:49.470986Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num4['price']=df_num3['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:49.501992Z",
     "start_time": "2021-04-25T10:41:49.486989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying R2s for the remaining variables\n",
    "r2_p(df_num4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:56.094990Z",
     "start_time": "2021-04-25T10:41:49.502992Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying correlations between predictors and the target\n",
    "jointplot(df_num4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:56.351047Z",
     "start_time": "2021-04-25T10:41:56.095990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using heatmap to visualize mutual relationships between predictors and their correlations with the target\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(df_num4.corr(), cmap=\"cubehelix\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:56.367051Z",
     "start_time": "2021-04-25T10:41:56.352047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking for correlations between the variables with pearson coefficient between 1 and 0.3\n",
    "\n",
    "\n",
    "df_coeff=df_num4.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "df_coeff['pairs'] = list(zip(df_coeff.level_0, df_coeff.level_1))\n",
    "df_coeff.set_index(['pairs'], inplace = True)\n",
    "df_coeff.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "df_coeff.columns = ['cc']\n",
    "df_coeff.drop_duplicates(inplace=True)\n",
    "df_coeff[((df_coeff.cc>.3) & (df_coeff.cc <1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T23:50:35.479689Z",
     "start_time": "2021-04-23T23:50:35.467687Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">Mutual correlation coefficients between the remaining independent variables are \n",
    "slightly higher or below 0.7. I am leaving sqft_living, grade, and bathroom variables in because of their logical connection with a property price despite their multicollinearity (0.74 & 0.73 are above the 0.7 threshold).<br>\n",
    "\n",
    "Therefore the remaining numerical variables for <u>modeling</u> are<br><br>\n",
    "<b>1. grade<br>\n",
    "2. bathrooms<br>\n",
    "3. sqft_living<br>\n",
    "4. distance<br></b>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:56.399058Z",
     "start_time": "2021-04-25T10:41:56.368052Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables: Investigating distributions and the raw correlations between the original, minimally processed predictor and the target (price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original categorical variables: waterfront, view, condition, basement_exists, renovation_done, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:56.415061Z",
     "start_time": "2021-04-25T10:41:56.400059Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a DataFrame with categorical variables\n",
    "\n",
    "df_cat1 = df_2.filter(['price','waterfront','view','condition','basement_exists','renovation_done','month'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual investigation of the box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:56.431065Z",
     "start_time": "2021-04-25T10:41:56.416062Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:57.976914Z",
     "start_time": "2021-04-25T10:41:56.432065Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names=['waterfront','view','condition','basement_exists','renovation_done','month']\n",
    "for col in names:\n",
    "    boxen_plot(df_cat1,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T05:32:12.820514Z",
     "start_time": "2021-04-18T05:31:18.446Z"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> Based on the plots, it is quite clear that 'month', 'condition' and 'basement_exists' variables do not affect the price of the properties and can be dropped from the categorical variables<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dumming out variables in the categorical DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:57.992421Z",
     "start_time": "2021-04-25T10:41:57.977915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using OheHotEncoder to dummy categorical out. Based on the boxplots above, I am leaving \n",
    "# 'month','basement_exists','condition' variables out, they seem not to have too much effect on the target.\n",
    "# The reason for removing 'waterfront' variable is a tiny porting of all properties in the dataset.\n",
    "\n",
    "ohe=OneHotEncoder(drop='first')\n",
    "df_cat_transform=ohe.fit_transform(df_cat1.drop(['price','month','basement_exists','condition','waterfront'], axis=1))\n",
    "df_cat1_trsfm=pd.DataFrame(df_cat_transform.todense(), \n",
    "                          columns=ohe.get_feature_names(['view','renovation_done']))\n",
    "df_cat1_trsfm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:58.024428Z",
     "start_time": "2021-04-25T10:41:57.993422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding a price column and resetting the index \n",
    "# Due to the removal of the extreme values in numerical values, some rows have Nan price values; these rows are dropped\n",
    "\n",
    "df_cat1_trsfm['price']=df_num4['price']\n",
    "\n",
    "df_cat1_trsfm=df_cat1_trsfm[df_cat1_trsfm.price.notna()]\n",
    "\n",
    "df_cat1_trsfm=df_cat1_trsfm.reset_index()\n",
    "\n",
    "df_cat1_trsfm=df_cat1_trsfm.drop('index', axis=1)\n",
    "\n",
    "df_cat1_trsfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>df_cat1_trsfm</b> DataFrame<br><br><b>19811</b> records out of original <b>21597</b> left\n",
    "    </div><br>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Index reset</b>\n",
    "    </div><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:58.040432Z",
     "start_time": "2021-04-25T10:41:58.032431Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cat1_trsfm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><i><b>“Everything should be made as simple as possible, but no simpler.”</b></i><div style=\"text-align: right\">Albert Einstein</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen baseline model is a model with only one numerical variable, grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:58.072439Z",
     "start_time": "2021-04-25T10:41:58.043433Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create the formula and  the model\n",
    "\n",
    "f  = 'price~grade'\n",
    "\n",
    "model_baseline = smf.ols(f, df_num4).fit()\n",
    "model_baseline.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:58.232475Z",
     "start_time": "2021-04-25T10:41:58.073440Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_baseline.resid,dist=stats.norm,fit=True,line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> The baseline model has a coefficient of determination of 0.452, indicating that roughly 45% of the observations fit the model. F-statistics is very high that indicates that the baseline model is a significant improvement of the  \"intercept only model\"<br>\n",
    "    The Skewness and the Kurtosis values indicate non-normal distribution of the target variable<br>\n",
    "    QQ plot is also indicative of the abnormal distribution of the residuals, especially in the upper Quantile\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 (all numerical variables considered significant, see Explore section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:58.264482Z",
     "start_time": "2021-04-25T10:41:58.233475Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a formula including the remaining numerical variables\n",
    "\n",
    "variables_to_include = ' + '.join(df_num4.drop('price',axis=1).columns)\n",
    "\n",
    "## Create the formula and  the model\n",
    "f  = \"price~\" + variables_to_include\n",
    "\n",
    "model_1 = smf.ols(f, df_num4).fit()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QQ plot: to access normality of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:41:58.439521Z",
     "start_time": "2021-04-25T10:41:58.265482Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_1.resid,dist=stats.norm,fit=True,line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "The summary of the model above indicates that<br>\n",
    "    1. All the independent variables coefficients and the intercept value are significant (p-values< 0.05)<br>\n",
    "    2. The coefficient of determination (R2) is not very high, but it is significantly higher than R2 of the baseline model. It indicates that about 66.8 percent of the observations fall within the regression line <br>\n",
    "    3. The skew and the Kurtosis values indicate the highly non-normal distribution of the target variable<br>\n",
    "    4. The high value of JB coefficient also indicates that the data is highly non-normal <br>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "From the model's QQ plot, it is also quite obvious that the 'price' target variable is not normally distributed. A steep swing up indicates that the higher-priced houses are less likely to fit the baseline model and are more spread out. One possible reason might be <b>an unusually large number of outliers in the dataset</b></div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>There are two potential approaches that can be taken</b><br>\n",
    "        1. Normalization by either log or square root transformation<br>\n",
    "        2. Removal of outliers</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Plot regression results against each regressor: accessing linearity of there relationship with the target and their homoscedasticity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:04.589146Z",
     "start_time": "2021-04-25T10:41:58.440522Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in (df_num4.drop('price',axis=1).columns):\n",
    "    fig = sm.graphics.plot_regress_exog(model_1, col, fig=plt.figure(figsize=(12,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> The results indicate that all of the predictors display linear relationship with the target. The distance, sqft_living and bathrooms variables display less  heteroscedasticity than the grade variable does.<br><br></div>\n",
    "<div class=\"alert alert-block alert-danger\"><b>There might be several appropriate ways to address this issue</b><br>\n",
    "    1. Log transformation of the target and/or independent variables<br>\n",
    "    2. Using either Generalized Least Squares or Weighted Least squares<br>\n",
    "    3. Bootstrapping<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 (adding categorical variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a model with all numerical variables and all categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:04.605096Z",
     "start_time": "2021-04-25T10:42:04.590093Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:04.621099Z",
     "start_time": "2021-04-25T10:42:04.606097Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cat1_trsfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:04.637103Z",
     "start_time": "2021-04-25T10:42:04.622100Z"
    }
   },
   "outputs": [],
   "source": [
    "# DatyaFrames to concatinate: df_cat1_trsfm AND df_num4\n",
    "df_num_cat_1 = pd.concat([df_num4, df_cat1_trsfm.drop('price',axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:05.770859Z",
     "start_time": "2021-04-25T10:42:04.638104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing multicollinearity in the new dataset\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(df_num_cat_1.corr(), cmap=\"cubehelix\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The matrix indicates no strong correlation between the price and any of the categorical variables. However, renovation_done_4 correlation is slightly higher than the rest of the categorical variables. Conceptually this variables indicative of a recent renovation or a newer property.</div>\n",
    "<div class=\"alert alert-block alert-danger\">There is no high expectations that adding the categorical variables to the mix will significantly improve the model</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:05.802867Z",
     "start_time": "2021-04-25T10:42:05.771861Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:05.850878Z",
     "start_time": "2021-04-25T10:42:05.803867Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a formula for the numerical variables from the basemodel\n",
    "# AND the categorical variables from the previous section\n",
    "\n",
    "variables_to_include = ' + '.join(df_num_cat_1.drop('price',axis=1).columns)\n",
    "\n",
    "## Create the formula and the model\n",
    "f  = \"price~\" + variables_to_include\n",
    "\n",
    "\n",
    "model_2 = smf.ols(f, df_num_cat_1).fit()\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.025917Z",
     "start_time": "2021-04-25T10:42:05.851878Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_2.resid,dist=stats.norm,fit=True,line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">The summary indicates a very slight improvement over the previous model, 66.9% versus 66.8% of all of the observations fall within the results of the line formed by the regression equation.<br><br>\n",
    "    It is also evident that p-values of most of the categorical values are very high, indicating their insignificance in the model. However, because they describe the same feature, I am leaving them in for now<br><br>\n",
    "The residuals normality did not improve</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 (preprocessing and removal of outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling with Robust Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "I ruled out the scaling of the data in this step of the process because it would not change the statistics of the mode, though the correlation coefficients would become more compatible with each other.\n",
    "<br><br>I am leaving the snippets in the notebook in case I reconsider.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\"><b>The next step is a removal of ourliers</b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.041920Z",
     "start_time": "2021-04-25T10:42:06.026918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using RobustScaler to scale the data\n",
    "\"\"\"# Using RobustScaler, which transforms the feature vector by subtracting the median and then dividing by the\n",
    "# interquartile range (%25-75%). It is the most robust to the ourliers\n",
    "\n",
    "df_for_scalers=df_num_cat_2.copy()\n",
    "\n",
    "cols=['bathrooms','grade','sqft_living15','distance','waterfront_1','renovation_done_4']\n",
    "scaler = RobustScaler()\n",
    "robust_df = scaler.fit_transform(df_for_scalers.drop('price',axis=1))\n",
    "robust_df = pd.DataFrame(robust_df, columns=cols)\n",
    "\n",
    "df_num_cat_2.describe()\"\"\"\n",
    "\n",
    "\"\"\"robust_df.describe()\"\"\"\n",
    "\n",
    "\"\"\"fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize =(20, 5))\n",
    "ax1.set_title('Before Scaling')\n",
    "  \n",
    "sns.kdeplot(df_for_scalers['distance'], ax = ax1, color ='blue')\n",
    "\n",
    "ax2.set_title('After Robust Scaling')\n",
    "  \n",
    "sns.kdeplot(robust_df['distance'], ax = ax2, color ='red')\n",
    "\n",
    "\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.057924Z",
     "start_time": "2021-04-25T10:42:06.042920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building and summary of the model with scaled data\n",
    "\"\"\"robust_df['price']=df_for_scalers['price']\n",
    "robust_df.info()\n",
    "\n",
    "\n",
    "num_cat_var2_robust = ' + '.join(robust_df.drop('price',axis=1).columns)\n",
    "\n",
    "## Create the formula and the model\n",
    "f  = \"price~\" + num_cat_var2_robust\n",
    "\n",
    "\n",
    "model_num_cat_2_robust = smf.ols(f, robust_df).fit()\n",
    "model_num_cat_2_robust.summary()\n",
    "\n",
    "coeffs=model_num_cat_2.params\n",
    "coeffs.sort_values().round(2)\n",
    "\n",
    "coeffs=model_num_cat_2_robust.params\n",
    "coeffs.sort_values().round(2)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removal of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IQR method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.089931Z",
     "start_time": "2021-04-25T10:42:06.058925Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.121938Z",
     "start_time": "2021-04-25T10:42:06.090932Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_2=df_num_cat_1.copy()\n",
    "\n",
    "# Due to the fact that discrete variables are not suitable for IQR method outlier removal, they are being dropped \n",
    "# from the DataFrame. They will be added back to the Dataframe for modeling\n",
    "\n",
    "df_num_cat_2=df_num_cat_2.drop(['view_1','view_2','view_3','view_4',\n",
    "                              'renovation_done_1','renovation_done_2','renovation_done_3','renovation_done_4',\n",
    "                              'grade','bathrooms'], axis=1)\n",
    "\n",
    "Q1 = df_num_cat_2.quantile(q=.25)\n",
    "Q3 = df_num_cat_2.quantile(q=.75)\n",
    "IQR = df_num_cat_2.apply(stats.iqr)\n",
    "\n",
    "df_num_cat_3 = df_num_cat_2[~((df_num_cat_2 < (Q1-1.5*IQR)) | (df_num_cat_2 > (Q3+1.5*IQR))).any(axis=1)]\n",
    "\n",
    "df_num_cat_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.137942Z",
     "start_time": "2021-04-25T10:42:06.122939Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_3['grade']=df_num_cat_1['grade']\n",
    "df_num_cat_3['bathrooms']=df_num_cat_1['bathrooms']\n",
    "df_num_cat_3['view_1']=df_num_cat_1['view_1']\n",
    "df_num_cat_3['view_2']=df_num_cat_1['view_2']\n",
    "df_num_cat_3['view_3']=df_num_cat_1['view_3']\n",
    "df_num_cat_3['view_4']=df_num_cat_1['view_4']\n",
    "df_num_cat_3['renovation_done_1']=df_num_cat_1['renovation_done_1']\n",
    "df_num_cat_3['renovation_done_2']=df_num_cat_1['renovation_done_2']\n",
    "df_num_cat_3['renovation_done_3']=df_num_cat_1['renovation_done_3']\n",
    "df_num_cat_3['renovation_done_4']=df_num_cat_1['renovation_done_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.153946Z",
     "start_time": "2021-04-25T10:42:06.138943Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.169949Z",
     "start_time": "2021-04-25T10:42:06.154945Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_3=df_num_cat_3.reset_index()\n",
    "\n",
    "df_num_cat_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.185952Z",
     "start_time": "2021-04-25T10:42:06.170950Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_3=df_num_cat_3.drop('index', axis=1)\n",
    "df_num_cat_3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>df_num_cat_3</b> DataFrame<br><br><b>18619</b> records out of the original <b>21597</b> left\n",
    "    </div><br>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Index reset</b>\n",
    "    </div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.233963Z",
     "start_time": "2021-04-25T10:42:06.186954Z"
    }
   },
   "outputs": [],
   "source": [
    "## Formula is the same, model is for the cleaned DF\n",
    "\n",
    "variables_to_include_3_1 = ' + '.join(df_num_cat_3.drop('price',axis=1).columns)\n",
    "f  = \"price~\" + variables_to_include_3_1\n",
    "\n",
    "\n",
    "model_3_1 = smf.ols(f, df_num_cat_3).fit()\n",
    "model_3_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.392999Z",
     "start_time": "2021-04-25T10:42:06.234964Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_3_1.resid,dist=stats.norm,fit=True,line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> While the IQR removal of outliers decreased the R squared of the model, it made the distribution more normal (Skew and Kurtosis values are almost within the normality ranges). This fact is also reflected by the QQ plot of the model residuals. Unfortunately, the Coefficient of determination dropped</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Z-score method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Z scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.409002Z",
     "start_time": "2021-04-25T10:42:06.393999Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.425006Z",
     "start_time": "2021-04-25T10:42:06.410003Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_4=df_num_cat_1.copy()\n",
    "\n",
    "df_num_cat_4=df_num_cat_4.drop(['view_1','view_2','view_3','view_4',\n",
    "                              'renovation_done_1','renovation_done_2','renovation_done_3','renovation_done_4',\n",
    "                              'grade','bathrooms'], axis=1)\n",
    "\n",
    "df_num_cat_4['z_sqft_living']=stats.zscore(df_num_cat_4['sqft_living'])\n",
    "df_num_cat_4['z_distance']=stats.zscore(df_num_cat_4['distance'])\n",
    "df_num_cat_4['z_price']=stats.zscore(df_num_cat_4['price'])\n",
    "\n",
    "df_num_cat_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.441009Z",
     "start_time": "2021-04-25T10:42:06.426007Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_5=df_num_cat_4[(abs(df_num_cat_4.z_price) < 3)]\n",
    "\n",
    "df_num_cat_5=df_num_cat_5[(abs(df_num_cat_5.z_distance) < 3)]\n",
    "\n",
    "df_num_cat_5=df_num_cat_5[(abs(df_num_cat_5.z_sqft_living) < 3)]\n",
    "df_num_cat_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.457013Z",
     "start_time": "2021-04-25T10:42:06.442010Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_5['grade']=df_num_cat_1['grade']\n",
    "df_num_cat_5['bathrooms']=df_num_cat_1['bathrooms']\n",
    "df_num_cat_5['view_1']=df_num_cat_1['view_1']\n",
    "df_num_cat_5['view_2']=df_num_cat_1['view_2']\n",
    "df_num_cat_5['view_3']=df_num_cat_1['view_3']\n",
    "df_num_cat_5['view_4']=df_num_cat_1['view_4']\n",
    "df_num_cat_5['renovation_done_1']=df_num_cat_1['renovation_done_1']\n",
    "df_num_cat_5['renovation_done_2']=df_num_cat_1['renovation_done_2']\n",
    "df_num_cat_5['renovation_done_3']=df_num_cat_1['renovation_done_3']\n",
    "df_num_cat_5['renovation_done_4']=df_num_cat_1['renovation_done_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.473016Z",
     "start_time": "2021-04-25T10:42:06.458013Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_5=df_num_cat_5.drop(['z_sqft_living','z_distance','z_price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.489020Z",
     "start_time": "2021-04-25T10:42:06.474017Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_5=df_num_cat_5.reset_index()\n",
    "df_num_cat_5=df_num_cat_5.drop('index', axis=1)\n",
    "df_num_cat_5.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>df_num_cat_5</b> DataFrame<br><br><b>19261</b> records out of the original <b>21597</b> left\n",
    "    </div><br>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Index reset</b>\n",
    "    </div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T00:52:55.142253Z",
     "start_time": "2021-04-21T00:52:55.123744Z"
    }
   },
   "source": [
    "##### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.537031Z",
     "start_time": "2021-04-25T10:42:06.490020Z"
    }
   },
   "outputs": [],
   "source": [
    "## Formula is the same, model is for the cleaned DF\n",
    "\n",
    "variables_to_include_3_2 = ' + '.join(df_num_cat_5.drop('price',axis=1).columns)\n",
    "f  = \"price~\" + variables_to_include_3_2\n",
    "\n",
    "\n",
    "model_3_2 = smf.ols(f, df_num_cat_5).fit()\n",
    "model_3_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.696066Z",
     "start_time": "2021-04-25T10:42:06.538031Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_3_2.resid,dist=stats.norm,fit=True,line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "The R squared of the model is 0.654 and F-statistics is higher than for the previous model\n",
    "    <br>The IQR method of outliers removal made the residual distribution more normal than Z-score method due to the former having more strict criteria. The decision is to use the dataset compiled after Z-score outlier removal. \n",
    "<br>\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\"><b>The next step is Log transformation of the target variable</b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 (Using log and square root transformations on the target variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.712070Z",
     "start_time": "2021-04-25T10:42:06.697067Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.760080Z",
     "start_time": "2021-04-25T10:42:06.713071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Log transform\n",
    "df_num_cat_5_log=df_num_cat_5.copy()\n",
    "\n",
    "df_num_cat_5_log['log_price'] = df_num_cat_5['price'].map(lambda x: np.log(x))\n",
    "df_num_cat_5_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:06.776084Z",
     "start_time": "2021-04-25T10:42:06.761082Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_5_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:07.462237Z",
     "start_time": "2021-04-25T10:42:06.777085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram of log_price and price\n",
    "continuous=['price','log_price']\n",
    "for col in continuous:\n",
    "    fig, ax =plt.subplots(figsize=(5, 5))\n",
    "    distribution(df_num_cat_5_log[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "The transformation worked well, improving the normality of the 'price' variable. Log_price distribution looks more symmetrical. Skewness improved dramatically (from 1.18 to -0.01, 0 being perfectly symmetrical)\n",
    "<br><br>\n",
    " Kurtosis value decreased, making the curve more Mesokurtic (close to a Gaussian curve). It is an expected effect of log transform.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\"><b>The next step is test a square root transformation.</b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:07.509248Z",
     "start_time": "2021-04-25T10:42:07.463238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Square transform\n",
    "df_num_cat_5_sqrt=df_num_cat_5.copy()\n",
    "\n",
    "df_num_cat_5_sqrt['sqrt_price'] = df_num_cat_5['price'].map(lambda x: np.sqrt(x))\n",
    "df_num_cat_5_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:08.196401Z",
     "start_time": "2021-04-25T10:42:07.510248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram of log_price and price\n",
    "continuous=['price','sqrt_price']\n",
    "for col in continuous:\n",
    "    fig, ax =plt.subplots(figsize=(5, 5))\n",
    "    distribution(df_num_cat_5_sqrt[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "The square root transformation also worked well in improving the normality of the 'price' variable. \n",
    "sqrt_price distribution looks more symmetrical. Skewness improved dramatically (from 1.18 to -0.59, 0 being perfectly symmetrical)\n",
    "<br><br>\n",
    " However, both of the parameters are worse that the parameters of log_price distribution.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\"><b>The next step is create two separate models and to see if the transformations made a difference</b><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model using log transformed target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:08.243916Z",
     "start_time": "2021-04-25T10:42:08.197402Z"
    }
   },
   "outputs": [],
   "source": [
    "## Formula is the same, model is for the cleaned DF\n",
    "\n",
    "variables_to_include_4_1 = ' + '.join(df_num_cat_5_log.drop(['price','log_price'],axis=1).columns)\n",
    "f  = \"log_price~\" + variables_to_include_4_1\n",
    "\n",
    "\n",
    "model_4_1 = smf.ols(f, df_num_cat_5_log).fit()\n",
    "model_4_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T02:19:24.434279Z",
     "start_time": "2021-04-21T02:18:25.206Z"
    }
   },
   "source": [
    "#### Model using square root transformed target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:08.290926Z",
     "start_time": "2021-04-25T10:42:08.244917Z"
    }
   },
   "outputs": [],
   "source": [
    "## Formula is the same, model is for the cleaned DF\n",
    "\n",
    "variables_to_include_4_2 = ' + '.join(df_num_cat_5_sqrt.drop(['price','sqrt_price'],axis=1).columns)\n",
    "f  = \"sqrt_price~\" + variables_to_include_4_2\n",
    "\n",
    "\n",
    "model_4_2= smf.ols(f, df_num_cat_5_sqrt).fit()\n",
    "model_4_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:08.450962Z",
     "start_time": "2021-04-25T10:42:08.291927Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_4_1.resid,dist=stats.norm,fit=True,line='45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:08.610998Z",
     "start_time": "2021-04-25T10:42:08.451963Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_4_2.resid,dist=stats.norm,fit=True,line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "Both models have improved the R squared and the F-statistics of the previous models. The residuals of both models display a close-to-normal distribution. Log transformation helped improve the upper part of the distribution, while square root transformation worked better in the lower part of the distribution. \n",
    "<br><br>\n",
    "R squared of the square root transformation-based model is slightly higher, while its kurtosis value is slightly worse than the kurtosis value of the log-transformed price model. The decision is to use the log-transformed target variable.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-danger\"><b>The next step is to remove unnecessary categorical variables, scale the remaining variables, and built the last model with coefficients in the regression model, which are easy to compare and interpret</b><br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:08.627001Z",
     "start_time": "2021-04-25T10:42:08.611999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing all categorical values with high p-values and renaming the renovation_done_4\n",
    "# to a more prominent name, reflective of the definition of the field (see Categorical variables subsection \n",
    "# in Exploring distributions and correlations section)\n",
    "\n",
    "df_num_cat_5_log_cropped=df_num_cat_5_log.copy()\n",
    "df_num_cat_5_log_cropped=df_num_cat_5_log_cropped.drop(['view_1','view_2','view_3','view_4','renovation_done_1',\n",
    "                                                'renovation_done_2','renovation_done_3'], axis=1)\n",
    "df_num_cat_5_log_cropped.rename(columns={'renovation_done_4': 'recent_renovation_new'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:08.643005Z",
     "start_time": "2021-04-25T10:42:08.628002Z"
    }
   },
   "outputs": [],
   "source": [
    "df_num_cat_5_log_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:09.810265Z",
     "start_time": "2021-04-25T10:42:08.644005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardizing the independent variables. I decided to do it manually due to a better control of the utput\n",
    "\n",
    "\n",
    "df_num_cat_5_log_cropped_st=df_num_cat_5_log_cropped.copy()\n",
    "\n",
    "\n",
    "lv_min=df_num_cat_5_log_cropped_st.sqft_living.min()\n",
    "lv_range=df_num_cat_5_log_cropped_st.sqft_living.max()-df_num_cat_5_log_cropped_st.sqft_living.min()\n",
    "distance_range=df_num_cat_5_log_cropped_st.distance.max()-df_num_cat_5_log_cropped_st.distance.min()\n",
    "distance_min=df_num_cat_5_log_cropped_st.distance.min()\n",
    "bathroom_range=df_num_cat_5_log_cropped_st.bathrooms.max()-df_num_cat_5_log_cropped_st.bathrooms.min()\n",
    "bathroom_min=df_num_cat_5_log_cropped_st.bathrooms.min()\n",
    "grade_range=df_num_cat_5_log_cropped_st.grade.max()-df_num_cat_5_log_cropped_st.grade.min()\n",
    "grade_min=df_num_cat_5_log_cropped_st.grade.min()\n",
    "\n",
    "\n",
    "df_num_cat_5_log_cropped_st['sqft_living_st']=df_num_cat_5_log_cropped_st.apply(lambda row: round((row.sqft_living-lv_min)/lv_range,3), axis=1)\n",
    "df_num_cat_5_log_cropped_st['distance_st']=df_num_cat_5_log_cropped_st.apply(lambda row: round((row.distance-distance_min)/distance_range,3), axis=1)\n",
    "df_num_cat_5_log_cropped_st['bathrooms_st']=df_num_cat_5_log_cropped_st.apply(lambda row: round((row.bathrooms-bathroom_min)/bathroom_range,3), axis=1)\n",
    "df_num_cat_5_log_cropped_st['grade_st']=df_num_cat_5_log_cropped_st.apply(lambda row: (row.grade-grade_min)/grade_range, axis=1)\n",
    "#df_num_cat_5_sqrt_cropped_st['recent_renovation_new_str']=df_num_cat_5_sqrt_cropped_st['recent_renovation_new'].astype('str')\n",
    "\n",
    "df_num_cat_5_log_cropped_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:09.842273Z",
     "start_time": "2021-04-25T10:42:09.811266Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Formula is the same, model is for the cleaned DF\n",
    "\n",
    "variables_to_include_4_3 = ' + '.join(df_num_cat_5_log_cropped_st.drop(\n",
    "    ['price','log_price','sqft_living','distance','grade','bathrooms'],axis=1).columns)\n",
    "f  = \"log_price~\" + variables_to_include_4_3\n",
    "print(f)\n",
    "model_4_3= smf.ols(f, df_num_cat_5_log_cropped_st).fit()\n",
    "model_4_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.845448Z",
     "start_time": "2021-04-25T10:42:09.843273Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model_4_3.resid,dist=stats.norm,fit=True,line='45')\n",
    "\n",
    "# Removing variable to simplify the display (categorical variable with only 2 values does not have\n",
    "# much use when plotted by regress_exog)\n",
    "# print(df_num_cat_5_log_cropped_st.drop(['price','log_price','recent_renovation_new',\n",
    "#                                        'sqft_living', 'distance', 'grade', 'bathrooms'],axis=1).columns)\n",
    "\n",
    "\n",
    "for col in (df_num_cat_5_log_cropped_st.drop(['price','log_price','recent_renovation_new',\n",
    "                                        'sqft_living', 'distance', 'grade', 'bathrooms'],axis=1).columns):\n",
    "    fig = sm.graphics.plot_regress_exog(model_4_3, col, fig=plt.figure(figsize=(12,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "\n",
    "The final linear regression model of a log of the price variable versus grade, bathrooms, distance from the center of the city, sqft_living space, and the indicator if a house has been renovated recently or a newer house has a Coefficient of Determination of 0.663. It is indicative of the fact that 66.3% of the sold properties fall within the results of the line formed by the regression equation. F-statistics displays the high value and the overall p-value much lower than the confidence interval \n",
    "<br><br>\n",
    "The independent variables used in the equation display a clear linear relationship with the target and homoscedasticity.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>The next step is to validate the model by using training and test datasets</b><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T04:57:07.099682Z",
     "start_time": "2021-04-20T04:57:06.741146Z"
    }
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.861452Z",
     "start_time": "2021-04-25T10:42:15.846448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "y=df_num_cat_5_log_cropped_st[['log_price']]\n",
    "X=df_num_cat_5_log_cropped_st.drop(['price','log_price','recent_renovation_new',\n",
    "                                        'sqft_living', 'distance', 'grade', 'bathrooms'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.877455Z",
     "start_time": "2021-04-25T10:42:15.862453Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.893459Z",
     "start_time": "2021-04-25T10:42:15.878456Z"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.909462Z",
     "start_time": "2021-04-25T10:42:15.894460Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets. Use the default split size\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.925466Z",
     "start_time": "2021-04-25T10:42:15.910463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model to train data\n",
    "linreg = LinearRegression()\n",
    "model=linreg.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions on training and test sets for y_hat\n",
    "y_hat_train=linreg.predict(X_train)\n",
    "y_hat_test=linreg.predict(X_test)\n",
    "\n",
    "# Calculate residuals\n",
    "train_residuals=y_hat_train-y_train\n",
    "test_residuals=y_hat_test-y_test\n",
    "\n",
    "# Calculate training and test RMSE\n",
    "train_mse = mean_squared_error(y_train, y_hat_train, squared=False)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test, squared=False)\n",
    "print('Train MSE:', round(train_mse,3))\n",
    "print('Test MSE:', round(test_mse,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.941470Z",
     "start_time": "2021-04-25T10:42:15.926467Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model.coef_, model.intercept_, model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.957473Z",
     "start_time": "2021-04-25T10:42:15.942469Z"
    }
   },
   "outputs": [],
   "source": [
    "price_target=df_num_cat_5_log_cropped_st[['log_price']]\n",
    "price_predictors= df_num_cat_5_log_cropped_st.drop(['price','log_price','recent_renovation_new',\n",
    "                                        'sqft_living', 'distance', 'grade', 'bathrooms'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.973477Z",
     "start_time": "2021-04-25T10:42:15.958474Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(price_target, linreg.predict(price_predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:15.989480Z",
     "start_time": "2021-04-25T10:42:15.974477Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(price_target, linreg.predict(price_predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:16.005484Z",
     "start_time": "2021-04-25T10:42:15.990480Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_squared_error(price_target, linreg.predict(price_predictors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Train MSE: 0.272<br>\n",
    "Test MSE: 0.272<br>\n",
    "Are equal down to the third decimal digit indicating a good agreement between the training and the test sets<br><br>\n",
    "<b>R</b> squared for for the prediction on the full dataset is the same as in model_4_3: 0.663<br>\n",
    "<b>Mean Absolute Error</b> for the prediction on the full dataset is 0.213 which is not great but acceptable. The best possible theoretical value is 0.<br>\n",
    "<b>Mean Squared Error</b> for the prediction on the full dataset is 0.074. The best possible theoretical value is 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:16.021488Z",
     "start_time": "2021-04-25T10:42:16.006484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Not sure if the results of this function are indicative of anything, but leaving it here for a possible future use\n",
    "\"\"\"mse, bias, var = bias_variance_decomp(model, X_train.values, y_train.values.flatten(), \n",
    "                                      X_test.values, y_test.values, num_rounds=200, random_seed=1, loss='mse')\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNterpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:16.037491Z",
     "start_time": "2021-04-25T10:42:16.022488Z"
    }
   },
   "outputs": [],
   "source": [
    "%%latex\n",
    "\n",
    "\\begin{align}\\ln\\left( {Price} \\right) = 12.366 + 1.265 \\cdot \\left( grade \\right) + \n",
    "1.080 \\cdot \\left( sqft\\_living \\right) - 0.989 \\cdot \\left( distance \\right) \n",
    "+ 0.060 \\cdot \\left( bathrooms \\right) - 0.035 \\cdot \\left( recent\\_renovation\\_new \\right) \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model has a reasonable predictive ability tested in the final step of the model validation. MSE, MAE, and R2 score along with the model p-values for all predictors indicate a good fit.<br><br>\n",
    "The most influential predictor is a **building grade**, following by a **living space footage**. Both factors are **positively correlated** with the price of the property. Both factors are within property owners' control when they are renovating their houses.<br>A **distance** from the center of the city is **negatively correlated** with the price of property, meaning the further away a property is, the lower is the price. It is not a controllable variable but is helpful for home buyers if the living space and the number of bedrooms/bathrooms are important.<br> A **number of bathrooms** has a **positive effect** on the price of a property, but it is not as strong as the first two factors. This fact indicates that the convenience of having multiple bathrooms is essential for potential buyers and should be taken into account when owners are planning a renovation.<br>\n",
    "The last predictor in the model is an indicator of whether a property **has been renovated recently or a new construction**. It is very **weakly negatively correlated** with the price variable. The negative correlation (reduction of the price) might be related to the following factors: newer properties, on the average, are of less building quality.<br>\n",
    "**The intercept** of the model is a **bias** of the model and can be interpreted as an offset of the model due to other factors not taken into account for various reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendations to property owners planning a renovation to their properties:**\n",
    "* Increase the living space of your property\n",
    "* Do the renovation with higher building quality\n",
    "* Consider adding a bathroom\n",
    "\n",
    "**Recommendations to potential buyers:**\n",
    "* Look for properties further away from the city center to make the best out of your property buying budget\n",
    "* Properties in some zipcodes of the city are more affordable than others at the same distance from the city center\n",
    "* Properties in some zipcodes of the city are more affordable than others with a better view, more considerable property lots, and with older houses of better quality construction if these factors are essential to a buyer\n",
    "\n",
    "**Limitations of the model:**\n",
    "* The original dataset does not include other important factors, and therefore the model is biased\n",
    "* Multiple linear regression models, while easily interpretable, are limited in their predictive ability\n",
    "* Some variables in the dataset are strongly correlated with each other, and that affect the predictive power of the model\n",
    "\n",
    "**Suggestion for future improvements**:\n",
    "* Add variables to the original dataset like kitchen renovation, average commute time, crime index, average nearby public school quality, etc.\n",
    "* Update the dataset with more current data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:16.132513Z",
     "start_time": "2021-04-25T10:42:16.038492Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test=X_test.copy()\n",
    "df_test['log_price']=y_test['log_price']\n",
    "df_test['recent_renovation_new']=df_num_cat_5_log_cropped_st['recent_renovation_new']\n",
    "df_test['sqft_living']=df_num_cat_5_log_cropped_st['sqft_living']\n",
    "df_test['distance']=df_num_cat_5_log_cropped_st['distance']\n",
    "df_test['grade']=df_num_cat_5_log_cropped_st['grade']\n",
    "df_test['bathrooms']=df_num_cat_5_log_cropped_st['bathrooms']\n",
    "df_test['price']=df_test.apply(lambda row: math.exp(row.log_price), axis=1)\n",
    "df_test['recent_renovation_new_str']=df_test['recent_renovation_new'].astype('str')\n",
    "#df_test=df_test.reset_index(drop='index')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:17.650858Z",
     "start_time": "2021-04-25T10:42:16.133513Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regplots for all four variables\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".6\"})\n",
    "fig, axes = plt.subplots(figsize=(20,20), ncols=2, nrows=2)\n",
    "\n",
    "g1=sns.regplot(data=df_test, x=\"sqft_living_st\", y=\"price\", color=\"#003300\", fit_reg=True,\n",
    "               ax=axes[0,0], line_kws={\"color\": \"red\", \"lw\":5});\n",
    "g2=sns.regplot(data=df_test, x=\"distance_st\", y=\"price\", color=\"#000066\", \n",
    "               ax=axes[0,1], line_kws={\"color\": \"red\", \"lw\":5});\n",
    "g3=sns.regplot(data=df_test, x=\"bathrooms_st\", y=\"price\", color=\"#009900\", \n",
    "               ax=axes[1,0], line_kws={\"color\": \"red\", \"lw\":5});\n",
    "g4=sns.regplot(data=df_test, x=\"grade_st\", y=\"price\", color=\"#0000ff\", \n",
    "               ax=axes[1,1], line_kws={\"color\": \"red\", \"lw\":5});\n",
    "\n",
    "axes[0,0].set_title(\"Prive vs Living Space\", fontsize=26);\n",
    "axes[0,0].set_ylabel('Price', fontsize=20)\n",
    "axes[0,0].set_xlabel('Living Footage, adjusted', fontsize=20)\n",
    "axes[0,0].set_xlim(-0.01, 1.0)\n",
    "ylabels = ['{:,.1f}'.format(x) + 'M' for x in g1.get_yticks()/1000000]\n",
    "axes[0,0].set_yticklabels(ylabels, size=15)\n",
    "axes[0,0].grid(color='lightgrey')\n",
    "\n",
    "axes[0,1].set_title(\"Price vs Distance from City Center\", fontsize=26);\n",
    "axes[0,1].set_ylabel('Price', fontsize=20)\n",
    "axes[0,1].set_xlabel('Distance, adjusted', fontsize=20)\n",
    "axes[0,1].set_xlim(-0.01, 1.0)\n",
    "ylabels = ['{:,.1f}'.format(x) + 'M' for x in g2.get_yticks()/1000000]\n",
    "axes[0,1].set_yticklabels(ylabels, size=15)\n",
    "axes[0,1].grid(color='lightgrey')\n",
    "\n",
    "axes[1,0].set_title(\"Price vs Number of Bathrooms\", fontsize=26);\n",
    "axes[1,0].set_ylabel('Price', fontsize=20)\n",
    "axes[1,0].set_xlabel('Number of Bathrooms, adjusted', fontsize=20)\n",
    "axes[1,0].set_xlim(-0.01, 1.0)\n",
    "ylabels = ['{:,.1f}'.format(x) + 'M' for x in g3.get_yticks()/1000000]\n",
    "axes[1,0].set_yticklabels(ylabels, size=15)\n",
    "axes[1,0].grid(color='lightgrey')\n",
    "\n",
    "axes[1,1].set_title(\"Price vs Building Grade\", fontsize=26);\n",
    "axes[1,1].set_ylabel('Price', fontsize=20)\n",
    "axes[1,1].set_xlabel('Building Grade, adjusted', fontsize=20)\n",
    "axes[1,1].set_xlim(-0.01, 1.0)\n",
    "ylabels = ['{:,.1f}'.format(x) + 'M' for x in g4.get_yticks()/1000000]\n",
    "axes[1,1].set_yticklabels(ylabels, size=15)\n",
    "axes[1,1].grid(color='lightgrey')\n",
    "\n",
    "\n",
    "plt.suptitle(\"Regression plots of Price vs Four Independent Variables\", size=30, c=\"Blue\")\n",
    "plt.tight_layout(pad=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:18.750562Z",
     "start_time": "2021-04-25T10:42:17.651859Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_test, x='sqft_living', y='price',  trendline='lowess', trendline_color_override='blue',\n",
    "                 color='grade', size='distance',width=1000, height=800, size_max=20, \n",
    "                 color_continuous_scale=px.colors.sequential.Blackbody_r,\n",
    "                 labels={\n",
    "                     \"price\": \"Price\",\n",
    "                     \"sqft_living\": \"Living Space (sq ft)\",\n",
    "                     \"grade\": \"Building Grade\"\n",
    "                  },\n",
    "                title=\"Correlation: Property Price vs Living Space Footage\",  template = \"plotly_dark\")\n",
    "\n",
    "fig.update_traces(marker=dict(\n",
    "            line=dict(\n",
    "                color='coral',\n",
    "                width=0.5\n",
    "            )))\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_size=18,\n",
    "    font_color=\"white\",\n",
    "    title_font_family=\"Arial\",\n",
    "    title_font_color=\"white\",\n",
    "\n",
    ")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:18.942109Z",
     "start_time": "2021-04-25T10:42:18.751562Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(df_test, x='bathrooms', y='price', color_continuous_scale=px.colors.sequential.Blackbody_r,\n",
    "                 size='sqft_living',size_max=20,\n",
    "                 trendline='lowess', trendline_color_override='blue', color='grade',\n",
    "                 width=1000, height=800, labels={\n",
    "                     \"price\": \"Price\",\n",
    "                     \"bathrooms\": \"Number of bathrooms\",\n",
    "                     \"grade\": \"Building Grade\"\n",
    "                 },\n",
    "                title=\"Correlation: Property Price vs Number of Bathrooms\",\n",
    "                 template = \"plotly_dark\")\n",
    "\n",
    "\n",
    "fig.update_traces(marker=dict(\n",
    "            line=dict(\n",
    "                color='coral',\n",
    "                width=0.5\n",
    "            )))\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_size=18,\n",
    "    font_color=\"white\",\n",
    "    title_font_family=\"Arial\",\n",
    "    title_font_color=\"white\",\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:19.774294Z",
     "start_time": "2021-04-25T10:42:18.943109Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_test, x='distance', y='price',  trendline='lowess', trendline_color_override='blue',\n",
    "                 color='grade', size='bathrooms',width=1000, height=800, size_max=20, \n",
    "                 color_continuous_scale=px.colors.sequential.Blackbody_r,\n",
    "                 labels={\n",
    "                     \"price\": \"Price\",\n",
    "                     \"distance\": \"Distance\",\n",
    "                     \"grade\": \"Building Grade\"\n",
    "                  },\n",
    "                title=\"Correlation: Property Price vs Distance from the City Center\",  template = \"plotly_dark\")\n",
    "\n",
    "fig.update_traces(marker=dict(\n",
    "            line=dict(\n",
    "                color='coral',\n",
    "                width=0.5\n",
    "            )))\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_size=18,\n",
    "    font_color=\"white\",\n",
    "    title_font_family=\"Arial\",\n",
    "    title_font_color=\"white\",\n",
    "\n",
    ")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:19.949839Z",
     "start_time": "2021-04-25T10:42:19.775295Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(df_test, x='sqft_living', y='price',  trendline='ols', trendline_color_override='yellow',\n",
    "                 color='recent_renovation_new_str', width=1000, height=800, size_max=20, \n",
    "                 labels={\n",
    "                     \"price\": \"Price\",\n",
    "                     \"sqft_living\": \"Living Space (sq ft)\",\n",
    "                     \"recent_renovation_new_str\": \"Newer(1)/Older(0)\"\n",
    "                  },\n",
    "                title=\"Correlation: Property Price vs Living Space Footage of newer vs older properties\",\n",
    "                 template = \"plotly_dark\")\n",
    "\n",
    "fig.update_traces(marker=dict(\n",
    "            line=dict(\n",
    "                color='coral',\n",
    "                width=0.5\n",
    "            )))\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_size=18,\n",
    "    font_color=\"white\",\n",
    "    title_font_family=\"Arial\",\n",
    "    title_font_color=\"white\",\n",
    "\n",
    ")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:20.125878Z",
     "start_time": "2021-04-25T10:42:19.950840Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_test, x='bathrooms', z='grade', y='sqft_living',\n",
    "              color='price', size='distance', size_max=50, opacity=1, width=1000, height=800,\n",
    "                   color_continuous_scale=px.colors.sequential.Blackbody_r, \n",
    "                   labels={\n",
    "                     \"bathrooms\": \"Number of Bathrooms\",\n",
    "                     \"sqft_living\": \"Living Space (sq ft)\",\n",
    "                     \"grade\": \"Grade\",\n",
    "                       \"price\": \"Price\"\n",
    "                  },\n",
    "                title=\"3D plot: Living Space Footage, Number of Bathrooms and Grade of Sold Properties\",\n",
    "                   template = \"plotly_dark\")\n",
    "\n",
    "fig.update_traces(marker=dict(\n",
    "            line=dict(\n",
    "                color='coral',\n",
    "                width=0.5\n",
    "            )))\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_size=16,\n",
    "    font_color=\"white\",\n",
    "    title_font_family=\"Arial\",\n",
    "    title_font_color=\"white\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:20.428946Z",
     "start_time": "2021-04-25T10:42:20.126879Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cut_off=df.copy()\n",
    "df_cut_off=df_cut_off[(df_cut_off['price']<1500000)]\n",
    "\n",
    "fig = px.scatter_mapbox(df_cut_off, lat=\"lat\", lon=\"long\", color=\"price\", \n",
    "                  color_continuous_scale=px.colors.sequential.Plasma, zoom=10, \n",
    "                        mapbox_style='open-street-map', width=900, height=900,\n",
    "                        title=\"Properties Sold in King County in 2014-2015\",\n",
    "                   template = \"plotly_dark\")\n",
    "\n",
    "fig.update_layout(\n",
    "    font_family=\"Arial\",\n",
    "    font_size=20,\n",
    "    font_color=\"white\",\n",
    "    title_font_family=\"Arial\",\n",
    "    title_font_color=\"white\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'y':0.98,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:20.461056Z",
     "start_time": "2021-04-25T10:42:20.430946Z"
    }
   },
   "outputs": [],
   "source": [
    "df_zipcode_viz=df.groupby('zipcode').mean()\n",
    "\n",
    "df_zipcode_viz=df_zipcode_viz.reset_index()\n",
    "\n",
    "df_zipcode_viz=df_zipcode_viz.drop(['id','sqft_above','sqft_basement','yr_renovated','lat','long'], axis=1)\n",
    "df_zipcode_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:21.627819Z",
     "start_time": "2021-04-25T10:42:20.462056Z"
    }
   },
   "outputs": [],
   "source": [
    "KC_zip_json=json.load(open('data/wa_washington_zip_codes_geo.min.json', 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:42:43.208227Z",
     "start_time": "2021-04-25T10:42:21.628820Z"
    }
   },
   "outputs": [],
   "source": [
    "map_choropleth_zip(df_zipcode_viz, 'price', \"Average Prices of Sold Properties per Zipcode (King County, 2014-2015)\", \n",
    "                   \"Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:43:05.315026Z",
     "start_time": "2021-04-25T10:42:43.210231Z"
    }
   },
   "outputs": [],
   "source": [
    "map_choropleth_zip(df_zipcode_viz, 'sqft_lot', \"Average Lot Size of Sold Properties per Zipcode (King County, 2014-2015)\",\n",
    "                   \"Lot size (sq ft)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:43:27.113544Z",
     "start_time": "2021-04-25T10:43:05.316025Z"
    }
   },
   "outputs": [],
   "source": [
    "map_choropleth_zip(df_zipcode_viz, 'yr_built', \"Average Year Built of Sold Properties per Zipcode (King County, 2014-2015)\", \n",
    "                   \"Year Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:43:48.845554Z",
     "start_time": "2021-04-25T10:43:27.114545Z"
    }
   },
   "outputs": [],
   "source": [
    "map_choropleth_zip(df_zipcode_viz, 'view', \"Average View Category of Sold Properties per Zipcode (King County, 2014-2015)\", \n",
    "                   \"View Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T10:44:10.972109Z",
     "start_time": "2021-04-25T10:43:48.846555Z"
    }
   },
   "outputs": [],
   "source": [
    "map_choropleth_zip(df_zipcode_viz, 'sqft_living', \"Average Living Space of Sold Properties per Zipcode (King County, 2014-2015)\", \n",
    "                   \"Living Space (sq ft) \")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "903.323px",
    "left": "0px",
    "top": "110px",
    "width": "301.198px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
